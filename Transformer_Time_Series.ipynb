{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtI7YJCCRNJPTuE0rg6qQY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/binlidaily/google_colab/blob/main/Transformer_Time_Series.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bo5MOsIGGmad"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    COLAB = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "except:\n",
        "    print(\"Note: not using Google CoLab\")\n",
        "    COLAB = False\n",
        "\n",
        "# Make use of a GPU or MPS (Apple) if one is available.  (see module 3.2)\n",
        "import torch\n",
        "has_mps = torch.backends.mps.is_built()\n",
        "device = \"mps\" if has_mps else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "names = ['year', 'month', 'day', 'dec_year', 'sn_value',\n",
        "         'sn_error', 'obs_num', 'unused1']\n",
        "df = pd.read_csv(\n",
        "    \"https://data.heatonresearch.com/data/t81-558/SN_d_tot_V2.0.csv\",\n",
        "    sep=';', header=None, names=names,\n",
        "    na_values=['-1'], index_col=False)"
      ],
      "metadata": {
        "id": "zW1lbp1NJcny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preprocessing\n",
        "start_id = max(df[df['obs_num'] == 0].index.tolist()) + 1\n",
        "df = df[start_id:].copy()\n",
        "df['sn_value'] = df['sn_value'].astype(float)\n",
        "df_train = df[df['year'] < 2000]\n",
        "df_test = df[df['year'] >= 2000]\n",
        "\n",
        "spots_train = df_train['sn_value'].to_numpy().reshape(-1, 1)\n",
        "spots_test = df_test['sn_value'].to_numpy().reshape(-1, 1)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "spots_train = scaler.fit_transform(spots_train).flatten().tolist()\n",
        "spots_test = scaler.transform(spots_test).flatten().tolist()"
      ],
      "metadata": {
        "id": "lhMW7xNhJm3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sequence Data Preparation\n",
        "SEQUENCE_SIZE = 10\n",
        "\n",
        "def to_sequences(seq_size, obs):\n",
        "    x = []\n",
        "    y = []\n",
        "    for i in range(len(obs) - seq_size):\n",
        "        window = obs[i:(i + seq_size)]\n",
        "        after_window = obs[i + seq_size]\n",
        "        x.append(window)\n",
        "        y.append(after_window)\n",
        "    return torch.tensor(x, dtype=torch.float32).view(-1, seq_size, 1), torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "x_train, y_train = to_sequences(SEQUENCE_SIZE, spots_train)\n",
        "x_test, y_test = to_sequences(SEQUENCE_SIZE, spots_test)\n",
        "\n",
        "# Setup data loaders for batch\n",
        "train_dataset = TensorDataset(x_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "test_dataset = TensorDataset(x_test, y_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "LpVAxiR8JqJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Positional Encoding for Transformer\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "id": "1mIlWSUzJ00B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model definition using Transformer\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, input_dim=1, d_model=64, nhead=4, num_layers=2, dropout=0.2):\n",
        "        super(TransformerModel, self).__init__()\n",
        "\n",
        "        self.encoder = nn.Linear(input_dim, d_model)\n",
        "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
        "        encoder_layers = nn.TransformerEncoderLayer(d_model, nhead)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
        "        self.decoder = nn.Linear(d_model, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.pos_encoder(x)\n",
        "        x = self.transformer_encoder(x)\n",
        "        x = self.decoder(x[:, -1, :])\n",
        "        return x\n",
        "\n",
        "model = TransformerModel().to(device)"
      ],
      "metadata": {
        "id": "CW81bVN_J4ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=3)\n",
        "\n",
        "epochs = 1000\n",
        "early_stop_count = 0\n",
        "min_val_loss = float('inf')\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for batch in train_loader:\n",
        "        x_batch, y_batch = batch\n",
        "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(x_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_losses = []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            x_batch, y_batch = batch\n",
        "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "            outputs = model(x_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            val_losses.append(loss.item())\n",
        "\n",
        "    val_loss = np.mean(val_losses)\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    if val_loss < min_val_loss:\n",
        "        min_val_loss = val_loss\n",
        "        early_stop_count = 0\n",
        "    else:\n",
        "        early_stop_count += 1\n",
        "\n",
        "    if early_stop_count >= 5:\n",
        "        print(\"Early stopping!\")\n",
        "        break\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}, Validation Loss: {val_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAozMIKUKHLh",
        "outputId": "b2d17dab-9ae2-413a-8e8d-bac2af4a3e62"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000, Validation Loss: 0.0427\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "model.eval()\n",
        "predictions = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        x_batch, y_batch = batch\n",
        "        x_batch = x_batch.to(device)\n",
        "        outputs = model(x_batch)\n",
        "        predictions.extend(outputs.squeeze().tolist())\n",
        "\n",
        "rmse = np.sqrt(np.mean((scaler.inverse_transform(np.array(predictions).reshape(-1, 1)) - scaler.inverse_transform(y_test.numpy().reshape(-1, 1)))**2))\n",
        "print(f\"Score (RMSE): {rmse:.4f}\")"
      ],
      "metadata": {
        "id": "RpNgN2v7KMoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5-H2VK4TKOvs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}